---
title: 正則化について
description: null
date: 2019-10-26T15:13:47.315Z
thumbnail: null
categories:
  - 機械学習
tags:
  - 理論
permalink: '01'
---
線形モデルを勉強している途中で**L1正則化**、**L2正則化**という言葉がよく出てくるが、わからなかったので調べた結果をメモします。

なお、[全人類がわかる統計学](https://to-kei.net/neural-network/regularization/)に記載されている解説が個人的に一番わかりやすかったです。

## 正則化の目的
トレーニングデータでは精度が高いが、テストデータではそこまで精度が高くない状態を**過学習**と呼ぶ。過学習を解消する（「汎化」と呼ぶ）ための代表的な方法は以下となる。  
- トレーニングデータをさらに集める
- 正則化を行う
- より単純なモデルを試す
+ データの次元を減らす

上記のうち２番目と４番目に対するアプローチがL1正則化とL2正則化である。

### L1正則化
L1正則化 ... 損失関数 + L1正則化項  
minf\(x\)+λ∑ni=1\|wi\|


### L２正則化
L2正則化 ... 損失関数 + L2正則化項  
minf\(x\)+λ2∑i=1n\|wi\|2






